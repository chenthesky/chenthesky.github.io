<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#3367D6"/>
  <link rel="apple-touch-icon" href="/icons-192.png">
  <link rel="manifest" href="/manifest.json">

  <script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://cdn.bootcss.com/jquery.pjax/2.0.1/jquery.pjax.min.js"></script>

 
  
  <meta name="generator" content="Hexo 7.1.1">

  
    <meta name="description" content="个人博客">
  

  

  
    <meta name="author" content="Ty Leo">
  

  

  

  <title>机器学习算法 | Ty Leo&#39;s BLOG</title>

  

  

  <!--mathjax latex数学公式显示支持-->
  
  

  

  

  
<link rel="stylesheet" href="/css/style.css">

</head>
<body>
  <div class="root-container" id="pjax-container">
    
<!-- header container -->
<header class="header-container post" id="pjax-container">
  
    <div class="post-image" style="background-image: url(https://qiniu.sukoshi.xyz/src/images/68686407_p0.jpg)"></div>
  

  <!-- navbar -->
<nav class="navbar">
  <div class="navbar-content" id="pjax-container">
    <!-- logo -->
    <div class="navbar-logo">
      <a href="/">
        
          Ty Leo&#39;s BLOG
        
      </a>
    </div>
    <!-- link -->
    <div class="navbar-link">
      <div class="navbar-btn">
        <div></div>
        <div></div>
        <div></div>
      </div>
      <ul class="navbar-list">
        
          <li class="navbar-list-item"><a href="/">首页</a></li>
        
          <li class="navbar-list-item"><a href="/message/">留言</a></li>
        
          <li class="navbar-list-item"><a href="/archives">归档</a></li>
        
          <li class="navbar-list-item"><a href="/categories">分类</a></li>
        
      </ul>
    </div>
  </div>
</nav>

  
  

  
  

  
  

  
  

  
  
    <div class="header-content">
      <div class="post-text layout-block">
        <div class="layout-margin">
          <h1 class="title-wrap">机器学习算法</h1>
          <h2 class="title-sub-wrap">
            <strong>Ty Leo</strong>
            <span>发布于</span>
            <time  class="article-date" datetime="2024-02-26T13:12:11.386Z" itemprop="datePublished">2024-02-26</time>
          </h2>
          
            <h2 class="last-time">
              <span>最后更新于</span>
              <time  class="article-updated" datetime="2024-02-27T08:11:31.526Z" itemprop="dateUpdated">2024-02-27</time>
            </h2>
          
          
          <ul class="wrap-list dark">
  
    <li><a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">📒 学习笔记</a></li>
  
</ul>
          <ul class="wrap-list dark">
  
    <li><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">🏷️ 机器学习</a></li>
  
    <li><a href="/tags/Python/">🏷️ Python</a></li>
  
</ul>
        </div>
      </div>
    </div>
  

  
  

</header>

    <!-- 文章 -->

<!-- 文章内容 -->
<div class="body-container">
  <article class="content-container layout-block post-container">
    <div class="article-info">
      
      
      
      
      <section class="article-entry markdown-body layout-margin content-padding--large soft-size--large soft-style--box">
        <h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">流程分析</span></span><br><span class="line"><span class="string"> 1.获取数据</span></span><br><span class="line"><span class="string"> 2.数据处理</span></span><br><span class="line"><span class="string">    缺失值处理</span></span><br><span class="line"><span class="string">    特征值-&gt;字典类型</span></span><br><span class="line"><span class="string"> 3.准备好特征值 目标值</span></span><br><span class="line"><span class="string"> 4.划分数据集</span></span><br><span class="line"><span class="string"> 5.特征工程:字典特征提取</span></span><br><span class="line"><span class="string"> 6.决策树预估器流程</span></span><br><span class="line"><span class="string"> 7.模型评估</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 获取数据</span></span><br><span class="line">titanic_data = pd.read_csv(<span class="string">&#x27;../titanic/titanic.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选特征值 目标值</span></span><br><span class="line">x = titanic_data[[<span class="string">&quot;pclass&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;sex&quot;</span>]]  <span class="comment"># 特征值</span></span><br><span class="line">y = titanic_data[<span class="string">&quot;survived&quot;</span>]  <span class="comment"># 目标值</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#数据处理</span></span><br><span class="line">x = x.copy()</span><br><span class="line">x[<span class="string">&quot;age&quot;</span>].fillna(x[<span class="string">&quot;age&quot;</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#缺失值处理</span></span><br><span class="line">titanic_data = titanic_data.replace(to_replace=<span class="string">&quot;NA&quot;</span>,value=np.nan)  <span class="comment">#将NA值替换为NAN</span></span><br><span class="line">    <span class="comment">#2.删除缺失样本</span></span><br><span class="line">titanic_data.dropna(inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(titanic_data.isnull().<span class="built_in">any</span>()) <span class="comment">#查看是否存在缺失值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 筛选特征值 目标值</span></span><br><span class="line">x = titanic_data[[<span class="string">&quot;pclass&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;sex&quot;</span>]]  <span class="comment"># 特征值</span></span><br><span class="line">y = titanic_data[<span class="string">&quot;survived&quot;</span>]  <span class="comment"># 目标值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转化成字典</span></span><br><span class="line">x = x.to_dict(orient=<span class="string">&quot;records&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=<span class="number">5</span> )  <span class="comment">#random_state=22随机数种子</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#字典特征抽取</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">transfer = DictVectorizer()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test  = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#决策树预估器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">estimator = DecisionTreeClassifier(criterion=<span class="string">&quot;entropy&quot;</span>)</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型评估  计算准确率</span></span><br><span class="line">score = estimator.score(x_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率为:&#x27;</span>,score)</span><br></pre></td></tr></table></figure>

<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">流程分析</span></span><br><span class="line"><span class="string"> 1.获取数据</span></span><br><span class="line"><span class="string"> 2.数据处理</span></span><br><span class="line"><span class="string">    缺失值处理</span></span><br><span class="line"><span class="string">    特征值-&gt;字典类型</span></span><br><span class="line"><span class="string"> 3.准备好特征值 目标值</span></span><br><span class="line"><span class="string"> 4.划分数据集</span></span><br><span class="line"><span class="string"> 5.特征工程:字典特征提取</span></span><br><span class="line"><span class="string"> 6.决策树预估器流程</span></span><br><span class="line"><span class="string"> 7.模型评估</span></span><br><span class="line"><span class="string"> 8.随机森林</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">titanic_data = pd.read_csv(<span class="string">&#x27;../titanic/titanic.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line"><span class="comment"># x[&quot;age&quot;].fillna(x[&quot;age&quot;].mean(), inplace=True)</span></span><br><span class="line"><span class="comment">#缺失值处理</span></span><br><span class="line">titanic_data = titanic_data.replace(to_replace=<span class="string">&quot;NA&quot;</span>,value=np.nan)  <span class="comment">#将NA值替换为NAN</span></span><br><span class="line"><span class="comment">#2.删除缺失样本</span></span><br><span class="line">titanic_data.dropna(inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(titanic_data.isnull().<span class="built_in">any</span>()) <span class="comment">#查看是否存在缺失值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#筛选特征值 目标值</span></span><br><span class="line">x = titanic_data[[<span class="string">&quot;pclass&quot;</span>, <span class="string">&quot;age&quot;</span>, <span class="string">&quot;sex&quot;</span>]]  <span class="comment"># 特征值</span></span><br><span class="line">y = titanic_data[<span class="string">&quot;survived&quot;</span>]  <span class="comment"># 目标值</span></span><br><span class="line"><span class="comment"># 转化成字典</span></span><br><span class="line">x = x.to_dict(orient=<span class="string">&quot;records&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=<span class="number">22</span>)  <span class="comment">#random_state=22随机数种子</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#字典特征抽取</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer</span><br><span class="line">transfer = DictVectorizer()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test  = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#随机森林</span></span><br><span class="line"><span class="comment">#from sklearn.ensemble import RandomForestClassifier</span></span><br><span class="line">estimator = RandomForestClassifier()</span><br><span class="line"><span class="comment">#加入网格验证搜索</span></span><br><span class="line"><span class="comment">#参数准备</span></span><br><span class="line">param_dict = &#123;<span class="string">&quot;n_estimators&quot;</span>: [<span class="number">120</span>, <span class="number">200</span>, <span class="number">300</span>, <span class="number">500</span>, <span class="number">800</span>, <span class="number">1200</span>],</span><br><span class="line">                  <span class="string">&quot;max_depth&quot;</span>: [<span class="number">5</span>, <span class="number">8</span>, <span class="number">15</span>, <span class="number">25</span>, <span class="number">30</span>]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_dict, cv=<span class="number">3</span>)</span><br><span class="line">estimator.fit(x_train, y_train)  <span class="comment"># 训练集里面的数据和目标值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 传入测试值通过前面的预估器获得预测值</span></span><br><span class="line">y_predict = estimator.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;预测值为:&quot;</span>, y_predict, <span class="string">&quot;\n真实值为:&quot;</span>, y_test, <span class="string">&quot;\n比较结果为:&quot;</span>, y_test == y_predict)</span><br><span class="line">score = estimator.score(x_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;准确率为: &quot;</span>, score)</span><br><span class="line"><span class="comment"># ------------------</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳参数:\n&quot;</span>, estimator.best_params_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳结果:\n&quot;</span>, estimator.best_score_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最佳估计器:\n&quot;</span>, estimator.best_estimator_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;交叉验证结果:\n&quot;</span>, estimator.cv_results_)</span><br></pre></td></tr></table></figure>
<h2 id="回归模型"><a href="#回归模型" class="headerlink" title="回归模型"></a>回归模型</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">synthetic_data</span>(<span class="params">w, b, num_examples</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成y = wX+b+噪声&quot;&quot;&quot;</span></span><br><span class="line">    X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (num_examples, <span class="built_in">len</span>(w)))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;X是一个均值为0,方差为1的随机数,(num_examples, len(w))是样本量和样本长度&quot;&quot;&quot;</span></span><br><span class="line">    y = torch.matmul(X, w) + b</span><br><span class="line">    y += torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, y.shape)</span><br><span class="line">    <span class="keyword">return</span> X, y.reshape((-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">true_w = torch.tensor([<span class="number">2</span>, -<span class="number">3.4</span>])</span><br><span class="line">true_b = <span class="number">4.2</span></span><br><span class="line">features, labels = synthetic_data(true_w, true_b, <span class="number">1000</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;以房价为例：label是真实售价；feature是预测label的两个因素。&quot;&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(features[<span class="number">0</span>], labels[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">plt.scatter(features[:, <span class="number">1</span>], labels, <span class="number">1</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">batch_size, features, labels</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;定义一个data_iter函数,该函数接受批量大小,特征矩阵features和标签向量labels作为输入,生成大小为batch_size的小批量&quot;&quot;&quot;</span></span><br><span class="line">    num_example = <span class="built_in">len</span>(features)  <span class="comment"># 样本数量</span></span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_example))</span><br><span class="line">    <span class="string">&quot;&quot;&quot;随机读取数据&quot;&quot;&quot;</span></span><br><span class="line">    random.shuffle(indices)  <span class="comment"># 打乱下标</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_example, batch_size):</span><br><span class="line">        batch_indices = torch.tensor(indices[i:<span class="built_in">min</span>(i + batch_size, num_example)])</span><br><span class="line">        <span class="keyword">yield</span> features[batch_indices], labels[batch_indices]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">10</span> <span class="comment">#batch_size:即一次训练所抓取的数据样本数量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">    <span class="built_in">print</span>(X, <span class="string">&#x27;\n&#x27;</span>, y)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;定义初始化模型&quot;&quot;&quot;</span></span><br><span class="line">w = torch.normal(<span class="number">0</span>, <span class="number">0.01</span>, size=(<span class="number">2</span>, <span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;requires_grad=True 的作用是让 backward 可以追踪这个参数并且计算它的梯度&quot;&quot;&quot;</span></span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;定义模型&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linreg</span>(<span class="params">X, w, b</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;&quot;线性回归&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> torch.matmul(X, w) + b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;定义损失函数&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">squared_loss</span>(<span class="params">y_hat, y</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;均方损失&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="number">2</span> / <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;定义优化算法&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sgd</span>(<span class="params">params, lr, batch_size</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;params是一个参数里面包含了w和d,lr为学习率&quot;&quot;&quot;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;小批量梯度下降&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> params <span class="keyword">in</span> params:</span><br><span class="line">            params -= lr * params.grad / batch_size</span><br><span class="line">            params.grad.zero_()  <span class="comment">#手动把梯度设为0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;_____________________________________________________________________________&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;训练过程&quot;&quot;&quot;</span></span><br><span class="line">lr = <span class="number">0.01</span> <span class="comment">#学习率</span></span><br><span class="line">num_epochs = <span class="number">10</span>   <span class="comment">#把整个数据扫三遍</span></span><br><span class="line">net = linreg  <span class="comment">#模型</span></span><br><span class="line">loss = squared_loss  <span class="comment">#均方损失</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;先把数据扫一遍&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter(batch_size, features, labels):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;再拿出一个批量大小的x和y&quot;&quot;&quot;</span></span><br><span class="line">        l = loss(net(X,w,b),y)</span><br><span class="line">        <span class="string">&quot;&quot;&quot;把下x,w,b放在模型中做预测,把预测值与真实值y来做损失&quot;&quot;&quot;</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;x,y是小批量损失,l的形状是(batch_size,1),而不是一个标量&quot;&quot;&quot;</span></span><br><span class="line">        l.<span class="built_in">sum</span>().backward()  <span class="comment">#求和之后算梯度</span></span><br><span class="line">        sgd([w,b],lr,batch_size)  <span class="comment">#使用参数的梯度更新参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        train_l = loss(net(features,w,b),labels)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>,loss <span class="subst">&#123;<span class="built_in">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;w的误差值:<span class="subst">&#123;true_w-w.reshape(true_w.shape)&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;b的误差值:<span class="subst">&#123;true_b-b&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="comment">#读取数据</span></span><br><span class="line">column_name = [<span class="string">&#x27;Sample code number&#x27;</span>, <span class="string">&#x27;Clump Thickness&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;Uniformity of Cell Size&#x27;</span>, <span class="string">&#x27;Uniformity of Cell Shape&#x27;</span>, <span class="string">&#x27;Marginal Adhesion&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;Single Epithelial Cell Size&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;Bare Nuclei&#x27;</span>, <span class="string">&#x27;Bland Chromatin&#x27;</span>,</span><br><span class="line">                   <span class="string">&#x27;Normal Nucleoli&#x27;</span>, <span class="string">&#x27;Mitoses&#x27;</span>, <span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;../cancer/breast-cancer-wisconsin.data&#x27;</span>,names=column_name)</span><br><span class="line">data.head()</span><br><span class="line"></span><br><span class="line"><span class="comment">#缺失值处理</span></span><br><span class="line">    <span class="comment">#1.替换?为nan</span></span><br><span class="line">data = data.replace(to_replace=<span class="string">&quot;?&quot;</span>,value=np.nan)</span><br><span class="line">    <span class="comment">#2.删除缺失样本</span></span><br><span class="line">data.dropna(inplace=<span class="literal">True</span>)</span><br><span class="line">data.isnull().<span class="built_in">any</span>()  <span class="comment">#不存在缺失值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">    <span class="comment">#1.筛选特征值和目标值</span></span><br><span class="line">x = data.iloc[:,<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">y = data[<span class="string">&quot;Class&quot;</span>]</span><br><span class="line">x.head()</span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(x,y)  <span class="comment">#将x,y传入  也就是特征值和目标值</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#特征工程 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">transfer = StandardScaler()</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test  = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">estimator  = LogisticRegression()</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#逻辑回归的模型参数:回归系数和偏置</span></span><br><span class="line"><span class="built_in">print</span>(estimator.coef_) <span class="comment">#回归系数</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(estimator.intercept_) <span class="comment">#偏置</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#模型评估  计算准确率</span></span><br><span class="line">score = estimator.score(x_test,y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;准确率为:&#x27;</span>,score)</span><br></pre></td></tr></table></figure>



<h2 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h2><h3 id="特征抽取"><a href="#特征抽取" class="headerlink" title="特征抽取"></a>特征抽取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment">#划分数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction <span class="keyword">import</span> DictVectorizer <span class="comment">#字典特征提取</span></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer,TfidfVectorizer <span class="comment">#文本特征提取</span></span><br><span class="line"><span class="keyword">import</span> jieba   <span class="comment">#中文分词</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">datasets_demo</span>():</span><br><span class="line">    iris = load_iris()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;特征值名字\n&#x27;</span>,iris.feature_names)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;特征值\n&#x27;</span>, iris.data,iris.data.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;目标值名字\n&#x27;</span>, iris.target)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集划分</span></span><br><span class="line">    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练集的特征值&quot;</span>,x_train,x_train.shape)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dict_demo</span>():<span class="comment">#字典特征提取</span></span><br><span class="line">    data =[&#123;<span class="string">&#x27;city&#x27;</span>:<span class="string">&#x27;北京&#x27;</span>,<span class="string">&#x27;temporary&#x27;</span>:<span class="number">100</span>&#125;,&#123;<span class="string">&#x27;city&#x27;</span>:<span class="string">&#x27;上海&#x27;</span>,<span class="string">&#x27;temporary&#x27;</span>:<span class="number">0</span>&#125;,&#123;<span class="string">&#x27;city&#x27;</span>:<span class="string">&#x27;深圳&#x27;</span>,<span class="string">&#x27;temporary&#x27;</span>:<span class="number">50</span>&#125;]</span><br><span class="line">    <span class="comment">#实例化转换器</span></span><br><span class="line">    transfer = DictVectorizer(sparse=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment">#调用fit_transform()</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;特征名字&quot;</span>,transfer.get_feature_names())</span><br><span class="line">    <span class="built_in">print</span>(data_new)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_demo</span>():       <span class="comment">#英文文本特征提取</span></span><br><span class="line"></span><br><span class="line">    data = [<span class="string">&quot;life is short,i like like python&quot;</span>,<span class="string">&quot;life is too long,i dislike python&quot;</span>]</span><br><span class="line">    transfer = CountVectorizer()  <span class="comment">#不能使用sparse=False 要生成二维数组可以使用sparse内部的toarray()方法</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(data_new.toarray())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;特征名字&quot;</span>,transfer.get_feature_names())</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cut_word</span>(<span class="params">text</span>):</span><br><span class="line"></span><br><span class="line">    text= <span class="string">&quot; &quot;</span>.join(<span class="built_in">list</span>(jieba.cut(text)))</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_chinese_demo2</span>():  <span class="comment">#中文文本提取</span></span><br><span class="line">    data = [<span class="string">&quot;燕子去了，有再来的时候；杨柳枯了，有再青的时候；桃花谢了，有再开的时候。&quot;</span>,</span><br><span class="line">            <span class="string">&quot;但是，聪明的，你告诉我，我们的日子为什么一去不复返呢？&quot;</span>,</span><br><span class="line">            <span class="string">&quot;——是有人偷了他们罢：那是谁？又藏在何处呢？是他们自己逃走了罢：现在又到了哪里呢？&quot;</span>]</span><br><span class="line">    data_new = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">        data_new.append(cut_word(sent))</span><br><span class="line">    transfer = CountVectorizer(stop_words=[<span class="string">&quot;有人&quot;</span>,<span class="string">&quot;现在&quot;</span>])  <span class="comment"># 不能使用sparse=False 要生成二维数组可以使用sparse内部的toarray()方法</span></span><br><span class="line">    data_final = transfer.fit_transform(data_new)</span><br><span class="line">    <span class="built_in">print</span>(data_final.toarray())  <span class="comment">#sparse内部的toarray()方法</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;特征名字&quot;</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tfidf_dem0</span>():  <span class="comment">#使用tfidf进行文本特征抽取</span></span><br><span class="line">    data = [<span class="string">&quot;燕子去了，有再来的时候；杨柳枯了，有再青的时候；桃花谢了，有再开的时候。&quot;</span>,</span><br><span class="line">            <span class="string">&quot;但是，聪明的，你告诉我，我们的日子为什么一去不复返呢？&quot;</span>,</span><br><span class="line">            <span class="string">&quot;——是有人偷了他们罢：那是谁？又藏在何处呢？是他们自己逃走了罢：现在又到了哪里呢？&quot;</span>]</span><br><span class="line">    data_new = []</span><br><span class="line">    <span class="keyword">for</span> sent <span class="keyword">in</span> data:</span><br><span class="line">        data_new.append(cut_word(sent))</span><br><span class="line">    transfer = TfidfVectorizer(stop_words=[<span class="string">&quot;有人&quot;</span>, <span class="string">&quot;现在&quot;</span>])  <span class="comment"># 不能使用sparse=False 要生成二维数组可以使用sparse内部的toarray()方法</span></span><br><span class="line">    data_final = transfer.fit_transform(data_new)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(data_final.toarray())  <span class="comment"># sparse内部的toarray()方法</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;特征名字&quot;</span>, transfer.get_feature_names())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">   tfidf_dem0()</span><br></pre></td></tr></table></figure>

<h3 id="特征预处理"><a href="#特征预处理" class="headerlink" title="特征预处理"></a>特征预处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler,StandardScaler  <span class="comment">#归一化 标准化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">minmax_demo</span>():  <span class="comment"># 归一化</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = pd.read_csv(<span class="string">&quot;../data/datingTestSet2.csv&quot;</span>)</span><br><span class="line">    data = data.iloc[:, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.实例化一个转换器</span></span><br><span class="line">    transfer=MinMaxScaler()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#3.调用fit_transform</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(data_new)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stand_demo</span>(): <span class="comment">#标准化  对数据进行无量纲化处理  (x-mean)/std标准差</span></span><br><span class="line">    <span class="comment"># 1.获取数据</span></span><br><span class="line">    data = pd.read_csv(<span class="string">&quot;../data/datingTestSet2.csv&quot;</span>)</span><br><span class="line">    data = data.iloc[:, :<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.实例化一个转换器</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.调用fit_transform</span></span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(data_new)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    stand_demo()</span><br></pre></td></tr></table></figure>

<h3 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> pearsonr</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">variance_demo</span>():  <span class="comment">#低方差特征过滤</span></span><br><span class="line">    data = pd.read_csv(<span class="string">&quot;../data/datingTestSet2.csv&quot;</span>)</span><br><span class="line">    data = data.iloc[:,<span class="number">0</span>:-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(data)</span><br><span class="line">    transfer = VarianceThreshold(threshold=<span class="number">3</span>)</span><br><span class="line">    data_new=transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(data_new,data_new.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算两个变量之间的相关系数</span></span><br><span class="line">    r=pearsonr(data[<span class="string">&quot;Liters&quot;</span>],data[<span class="string">&quot;Consumtime&quot;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;相关系数&quot;</span>,r)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pca_demo</span>():  <span class="comment">#pca降维适用于  特征冗杂</span></span><br><span class="line">    data = [[<span class="number">2</span>,<span class="number">8</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">6</span>,<span class="number">3</span>,<span class="number">0</span>,<span class="number">8</span>],[<span class="number">5</span>,<span class="number">4</span>,<span class="number">9</span>,<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">    transfer = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line">    data_new=transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(data_new,data_new.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment">#案例分析</span></span><br><span class="line"><span class="comment">#1.数据获取</span></span><br><span class="line"><span class="comment">#2.合并表</span></span><br><span class="line"><span class="comment">#3.找到user_id和aisle之间的关系</span></span><br><span class="line"><span class="comment">#4.pca降维</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">case_test</span>():</span><br><span class="line">    <span class="comment"># 1.数据获取</span></span><br><span class="line">    aisles = pd.read_csv(<span class="string">&quot;../data/instacart/aisles.csv&quot;</span>)</span><br><span class="line">    orders = pd.read_csv(<span class="string">&quot;../data/instacart/orders.csv&quot;</span>)</span><br><span class="line">    order_products = pd.read_csv(<span class="string">&quot;../data/instacart/order_products__prior.csv&quot;</span>)</span><br><span class="line">    products = pd.read_csv(<span class="string">&quot;../data/instacart/products.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.合并表</span></span><br><span class="line">    <span class="comment">#合并aisles 和products 让aisles和products_id在一起</span></span><br><span class="line">    tab1 = pd.merge(aisles,products,on=[<span class="string">&quot;aisle_id&quot;</span>,<span class="string">&quot;aisle_id&quot;</span>])</span><br><span class="line">    tab2 = pd.merge(tab1, order_products, on=[<span class="string">&quot;product_id&quot;</span>, <span class="string">&quot;product_id&quot;</span>]) <span class="comment">#按照什么值</span></span><br><span class="line">    tab3 = pd.merge(tab2, orders, on=[<span class="string">&quot;order_id&quot;</span>, <span class="string">&quot;order_id&quot;</span>])</span><br><span class="line">    <span class="built_in">print</span>(tab3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.找到user_id和aisle之间的关系</span></span><br><span class="line">    table=pd.crosstab(tab3[<span class="string">&quot;aisle&quot;</span>],tab3[<span class="string">&quot;user_id&quot;</span>])</span><br><span class="line">    data = table</span><br><span class="line">    <span class="comment">#4.pca降维</span></span><br><span class="line">    transfer = PCA(n_components=<span class="number">0.95</span>)</span><br><span class="line">    data_new = transfer.fit_transform(data)</span><br><span class="line">    <span class="built_in">print</span>(data_new, data_new.shape)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">   case_test()</span><br></pre></td></tr></table></figure>

<h2 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;鸢尾花数据预测KNN</span></span><br><span class="line"><span class="string">1.获取数据</span></span><br><span class="line"><span class="string">2.划分数据集</span></span><br><span class="line"><span class="string">3.特征工程</span></span><br><span class="line"><span class="string">    预处理标准化</span></span><br><span class="line"><span class="string">4.KNN预估器流程</span></span><br><span class="line"><span class="string">5.模型评估</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">knn_iris</span>():</span><br><span class="line"><span class="comment">#1.获取数据</span></span><br><span class="line"><span class="comment">#from sklearn.datasets import load_iris</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.划分数据集</span></span><br><span class="line"><span class="comment">#from sklearn.model_selection import train_test_split</span></span><br><span class="line">    x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target,random_state=<span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.特征工程</span></span><br><span class="line">    <span class="comment">#标准化</span></span><br><span class="line"><span class="comment">#from sklearn.preprocessing import StandardScaler</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.KNN预估器流程</span></span><br><span class="line"><span class="comment">#from sklearn.neighbors import KNeighborsClassifier</span></span><br><span class="line">    estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>) <span class="comment">#1</span></span><br><span class="line">    estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#6.模型评估</span></span><br><span class="line">    score = estimator.score(x_test,y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为:&quot;</span>,score)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">knn_iris_gccv</span>():  <span class="comment">#网格验证和交叉搜索</span></span><br><span class="line"><span class="comment">#1.获取数据</span></span><br><span class="line"><span class="comment">#from sklearn.datasets import load_iris</span></span><br><span class="line">    iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment">#2.划分数据集</span></span><br><span class="line"><span class="comment">#from sklearn.model_selection import train_test_split</span></span><br><span class="line">    x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target,random_state=<span class="number">22</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#3.特征工程</span></span><br><span class="line">    <span class="comment">#标准化</span></span><br><span class="line"><span class="comment">#from sklearn.preprocessing import StandardScaler</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.KNN预估器流程</span></span><br><span class="line"><span class="comment">#from sklearn.neighbors import KNeighborsClassifier</span></span><br><span class="line">    estimator = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#网格验证和交叉搜索</span></span><br><span class="line">    <span class="comment">#参数准备</span></span><br><span class="line">    param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>:[<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">11</span>,<span class="number">13</span>]&#125;</span><br><span class="line">    estimator=GridSearchCV(estimator,param_grid=param_dict,cv=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.模型评估</span></span><br><span class="line">    score = estimator.score( x_test,y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为:\n&quot;</span>,score)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳参数:best_paparms_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳参数为:\n&quot;</span>,estimator.best_params_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳结果:best_score_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳结果:\n&quot;</span>,estimator.best_score_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳估计器:best_estimator_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳估计器:\n&quot;</span>,estimator.best_estimator_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳交叉验证:cv_results_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳交叉验证\n&quot;</span>, estimator.cv_results_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    knn_iris_gccv()</span><br></pre></td></tr></table></figure>

<h3 id="facebook实例"><a href="#facebook实例" class="headerlink" title="facebook实例"></a>facebook实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1.获取数据</span></span><br><span class="line"><span class="string">2.数据处理</span></span><br><span class="line"><span class="string">目的:</span></span><br><span class="line"><span class="string">    特征值x</span></span><br><span class="line"><span class="string">    目标值y</span></span><br><span class="line"><span class="string">    a.缩小数据范围</span></span><br><span class="line"><span class="string">     2&lt;x&lt;2.5</span></span><br><span class="line"><span class="string">     1&lt;y&lt;1.5</span></span><br><span class="line"><span class="string">    b.time-&gt; 年月日时分秒</span></span><br><span class="line"><span class="string">    c.过滤签到少的地点</span></span><br><span class="line"><span class="string">3.特征工程:标准化</span></span><br><span class="line"><span class="string">4.KNN算法预估流程</span></span><br><span class="line"><span class="string">5.模型的选择与调优</span></span><br><span class="line"><span class="string">6.模型评估</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">face_book_demo</span>():</span><br><span class="line"><span class="comment">#1.获取数据</span></span><br><span class="line">    data=pd.read_csv(<span class="string">&#x27;../data/FBlocation/train.csv&#x27;</span>)</span><br><span class="line"><span class="comment">#2.缩小数据范围</span></span><br><span class="line">    data = data.query(<span class="string">&quot;x&gt;2.0&amp;x&lt;2.5&amp;y&gt;1.0&amp;y&lt;1.5&quot;</span>)</span><br><span class="line">    time_value=pd.to_datetime(data[<span class="string">&quot;time&quot;</span>],unit=<span class="string">&quot;s&quot;</span>)  <span class="comment">#time-&gt; 年月日时分秒</span></span><br><span class="line">    date = pd.DatetimeIndex(time_value)</span><br><span class="line">    data[<span class="string">&quot;day&quot;</span>] = date.day</span><br><span class="line">    data[<span class="string">&quot;weekday&quot;</span>] = date.weekday</span><br><span class="line">    data[<span class="string">&quot;hour&quot;</span>] = date.hour</span><br><span class="line"></span><br><span class="line">    place_count= data.groupby(<span class="string">&quot;place_id&quot;</span>).count()[<span class="string">&quot;row_id&quot;</span>]</span><br><span class="line"></span><br><span class="line">    data_final=data[data[<span class="string">&quot;place_id&quot;</span>].isin(place_count[place_count&gt;<span class="number">3</span>].index.values)]</span><br><span class="line"><span class="comment">#筛选特征值目标值</span></span><br><span class="line">    x = data_final[[<span class="string">&quot;x&quot;</span>,<span class="string">&quot;y&quot;</span>,<span class="string">&quot;accuracy&quot;</span>,<span class="string">&quot;hour&quot;</span>,<span class="string">&quot;weekday&quot;</span>,<span class="string">&quot;day&quot;</span>]]</span><br><span class="line">    y = data_final[<span class="string">&quot;place_id&quot;</span>]</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment">#数据集划分</span></span><br><span class="line"></span><br><span class="line">    x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=<span class="number">22</span>)</span><br><span class="line"><span class="comment">#特征工程</span></span><br><span class="line">    <span class="comment">#标准化</span></span><br><span class="line"><span class="comment">#from sklearn.preprocessing import StandardScaler</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.KNN预估器流程</span></span><br><span class="line"><span class="comment">#from sklearn.neighbors import KNeighborsClassifier</span></span><br><span class="line">    estimator = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#网格验证和交叉搜索</span></span><br><span class="line">    <span class="comment">#参数准备</span></span><br><span class="line">    param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>:[<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">11</span>]&#125;</span><br><span class="line">    estimator=GridSearchCV(estimator,param_grid=param_dict,cv=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.模型评估</span></span><br><span class="line">    score = estimator.score( x_test,y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为:\n&quot;</span>,score)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳参数:best_paparms_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳参数为:\n&quot;</span>,estimator.best_params_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳结果:best_score_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳结果:\n&quot;</span>,estimator.best_score_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳估计器:best_estimator_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳估计器:\n&quot;</span>,estimator.best_estimator_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳交叉验证:cv_results_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳交叉验证\n&quot;</span>, estimator.cv_results_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    face_book_demo()</span><br></pre></td></tr></table></figure>

<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1.获取数据</span></span><br><span class="line"><span class="string">2.数据处理</span></span><br><span class="line"><span class="string">目的:</span></span><br><span class="line"><span class="string">    特征值x</span></span><br><span class="line"><span class="string">    目标值y</span></span><br><span class="line"><span class="string">    a.缩小数据范围</span></span><br><span class="line"><span class="string">     2&lt;x&lt;2.5</span></span><br><span class="line"><span class="string">     1&lt;y&lt;1.5</span></span><br><span class="line"><span class="string">    b.time-&gt; 年月日时分秒</span></span><br><span class="line"><span class="string">    c.过滤签到少的地点</span></span><br><span class="line"><span class="string">3.特征工程:标准化</span></span><br><span class="line"><span class="string">4.KNN算法预估流程</span></span><br><span class="line"><span class="string">5.模型的选择与调优</span></span><br><span class="line"><span class="string">6.模型评估</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">face_book_demo</span>():</span><br><span class="line"><span class="comment">#1.获取数据</span></span><br><span class="line">    data=pd.read_csv(<span class="string">&#x27;../data/FBlocation/train.csv&#x27;</span>)</span><br><span class="line"><span class="comment">#2.缩小数据范围</span></span><br><span class="line">    data = data.query(<span class="string">&quot;x&gt;2.0&amp;x&lt;2.5&amp;y&gt;1.0&amp;y&lt;1.5&quot;</span>)</span><br><span class="line">    time_value=pd.to_datetime(data[<span class="string">&quot;time&quot;</span>],unit=<span class="string">&quot;s&quot;</span>)  <span class="comment">#time-&gt; 年月日时分秒</span></span><br><span class="line">    date = pd.DatetimeIndex(time_value)</span><br><span class="line">    data[<span class="string">&quot;day&quot;</span>] = date.day</span><br><span class="line">    data[<span class="string">&quot;weekday&quot;</span>] = date.weekday</span><br><span class="line">    data[<span class="string">&quot;hour&quot;</span>] = date.hour</span><br><span class="line"></span><br><span class="line">    place_count= data.groupby(<span class="string">&quot;place_id&quot;</span>).count()[<span class="string">&quot;row_id&quot;</span>]</span><br><span class="line"></span><br><span class="line">    data_final=data[data[<span class="string">&quot;place_id&quot;</span>].isin(place_count[place_count&gt;<span class="number">3</span>].index.values)]</span><br><span class="line"><span class="comment">#筛选特征值目标值</span></span><br><span class="line">    x = data_final[[<span class="string">&quot;x&quot;</span>,<span class="string">&quot;y&quot;</span>,<span class="string">&quot;accuracy&quot;</span>,<span class="string">&quot;hour&quot;</span>,<span class="string">&quot;weekday&quot;</span>,<span class="string">&quot;day&quot;</span>]]</span><br><span class="line">    y = data_final[<span class="string">&quot;place_id&quot;</span>]</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment">#数据集划分</span></span><br><span class="line"></span><br><span class="line">    x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=<span class="number">22</span>)</span><br><span class="line"><span class="comment">#特征工程</span></span><br><span class="line">    <span class="comment">#标准化</span></span><br><span class="line"><span class="comment">#from sklearn.preprocessing import StandardScaler</span></span><br><span class="line">    transfer = StandardScaler()</span><br><span class="line">    x_train = transfer.fit_transform(x_train)</span><br><span class="line">    x_test = transfer.transform(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#4.KNN预估器流程</span></span><br><span class="line"><span class="comment">#from sklearn.neighbors import KNeighborsClassifier</span></span><br><span class="line">    estimator = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#网格验证和交叉搜索</span></span><br><span class="line">    <span class="comment">#参数准备</span></span><br><span class="line">    param_dict = &#123;<span class="string">&quot;n_neighbors&quot;</span>:[<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">9</span>,<span class="number">11</span>]&#125;</span><br><span class="line">    estimator=GridSearchCV(estimator,param_grid=param_dict,cv=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    estimator.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#5.模型评估</span></span><br><span class="line">    score = estimator.score( x_test,y_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;准确率为:\n&quot;</span>,score)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳参数:best_paparms_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳参数为:\n&quot;</span>,estimator.best_params_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳结果:best_score_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳结果:\n&quot;</span>,estimator.best_score_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳估计器:best_estimator_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳估计器:\n&quot;</span>,estimator.best_estimator_)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#最佳交叉验证:cv_results_</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;最佳交叉验证\n&quot;</span>, estimator.cv_results_)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    face_book_demo()</span><br></pre></td></tr></table></figure>

      </section>

      
      
        <nav class="article-nav">
          
            <div class="article-nav-item layout-padding">
  <article class="card-container article-nav-card content-padding--primary soft-size--large soft-style--box">
    
    <div class="card-text">
      
        <a href="/blogs/437d.html" itemprop="url">
          <h2 class="card-text--title text-ellipsis">爬虫</h2>
        </a>
      
      <div class="card-text--row">Newer</div>
    </div>
  </article>
</div>
          
          
            <div class="article-nav-item layout-padding">
  <article class="card-container article-nav-card content-padding--primary soft-size--large soft-style--box">
    
    <div class="card-text">
      
        <a href="/blogs/74cc.html" itemprop="url">
          <h2 class="card-text--title text-ellipsis">SQL</h2>
        </a>
      
      <div class="card-text--row">Older</div>
    </div>
  </article>
</div>
          
        </nav>
      

      <section class="page-message-container layout-padding">
        


      </section>
    </div>
    <div class="widget-info">
      <section class="widget-author widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-body">
    
      <img src="https://img.picui.cn/free/2024/07/08/668bee87db0a4.png" class="soft-size--round soft-style--box" alt="Ty Leo">
    
    
      <h2>Ty Leo</h2>
    
    
      <p>学习新思想，争做好青年</p>
    

    <div class="count-box">
      <div class="count-box--item">
        <svg class="icon icon-article" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M240.51564747 647.74217627h196.07203239c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806V165.10332731c0-33.18142087-30.16492806-60.32985613-60.32985612-60.32985611H245.04038668C225.43318342 104.7734712 210.35071939 119.85593522 210.35071939 139.46313845V617.57724821c0 16.59071043 13.57421762 30.16492806 30.16492808 30.16492806z m663.62841731-452.47392089v482.63884894c0 33.18142087-27.14843525 60.32985613-60.32985612 60.32985613H180.18579134c-33.18142087 0-60.32985613-27.14843525-60.32985612-60.32985613V195.26825538c-49.77213131 0-90.49478418 40.72265287-90.49478417 90.49478417v452.4739209c0 49.77213131 40.72265287 90.49478418 90.49478417 90.49478417h286.56681657c16.59071043 0 30.16492806 13.57421762 30.16492807 30.16492807s13.57421762 30.16492806 30.16492805 30.16492806h90.49478418c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806s13.57421762-30.16492806 30.16492807-30.16492807h286.56681657c49.77213131 0 90.49478418-40.72265287 90.49478417-90.49478417V285.76303955c0-49.77213131-40.72265287-90.49478418-90.49478417-90.49478417zM587.41232014 647.74217627h191.54729318c19.60720323 0 34.68966726-15.08246403 34.68966729-34.68966727V134.93839925c0-16.59071043-13.57421762-30.16492806-30.16492808-30.16492805H617.57724821c-30.16492806 0-60.32985613 27.14843525-60.32985612 60.32985611v452.4739209c0 16.59071043 13.57421762 30.16492806 30.16492805 30.16492806z" fill="currentColor"></path>
</svg>
        <span>21</span>
      </div>
      <div class="count-box--item">
        <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
        2
      </div>
      <div class="count-box--item">
        <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
        6
      </div>
    </div>
  </div>
</section>

      
<section class="widget-toc widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-toc" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M134.50666666 767.46666668H460.8c27.73333333 0 50.24000001 22.50666668 50.24000001 50.23999999v50.13333333c0 27.73333333-22.50666668 50.24000001-50.24000001 50.24000001H134.50666666c-27.73333333 0-50.24000001-22.50666668-50.23999999-50.24000001v-50.13333333c0.10666668-27.73333333 22.50666668-50.24000001 50.24000001-50.24000001zM84.37333332 541.65333333h326.18666669c27.73333333 0 50.24000001 22.39999999 50.23999999 50.13333334v50.24000001c0 27.73333333-22.50666668 50.24000001-50.24000002 50.23999999H84.37333332c-27.73333333 0-50.24000001-22.50666668-50.23999999-50.23999999v-50.24000001c0-27.73333333 22.50666668-50.13333334 50.24000001-50.13333334zM134.50666666 315.83999999H460.8c27.73333333 0 50.24000001 22.50666668 50.24000001 50.24000001v50.24000001c0 27.73333333-22.50666668 50.13333334-50.24000001 50.13333333H134.50666666c-27.73333333 0-50.24000001-22.39999999-50.23999999-50.13333333v-50.24000001c0.10666668-27.84000001 22.50666668-50.24000001 50.24000001-50.23999999zM209.81333332 89.91999999h326.18666671c27.73333333 0 50.24000001 22.39999999 50.23999997 50.13333335v50.23999999c0 27.73333333-22.50666668 50.24000001-50.24000001 50.24000001H209.81333332c-27.73333333 0-50.24000001-22.50666668-50.23999999-50.24000001v-50.24000001c0-27.73333333 22.50666668-50.13333334 50.24000001-50.13333333zM692.05333333 623.36l274.66666669 176.00000002c23.36000001 14.93333333 30.08 45.97333334 15.14666666 69.33333332L954.77333334 910.93333333c-14.93333333 23.25333334-45.97333334 30.08-69.33333335 15.14666667l-274.66666666-176c-23.36000001-14.93333333-30.08-45.97333334-15.14666667-69.33333333l27.09333334-42.24000001c14.93333333-23.36000001 46.08000001-30.08 69.33333333-15.14666666z" fill="currentColor"></path>
</svg>
    <span>TOC</span>
  </div>
  <div class="widget-body">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">1.</span> <span class="toc-text">决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">2.</span> <span class="toc-text">随机森林</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">回归模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">3.1.</span> <span class="toc-text">线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">3.2.</span> <span class="toc-text">逻辑回归</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">特征工程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96"><span class="toc-number">4.1.</span> <span class="toc-text">特征抽取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">4.2.</span> <span class="toc-text">特征预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E9%99%8D%E7%BB%B4"><span class="toc-number">4.3.</span> <span class="toc-text">特征降维</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#KNN"><span class="toc-number">5.</span> <span class="toc-text">KNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#facebook%E5%AE%9E%E4%BE%8B"><span class="toc-number">5.1.</span> <span class="toc-text">facebook实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-number">6.</span> <span class="toc-text">朴素贝叶斯</span></a></li></ol>
  </div>
</section>



      

      <section class="widget-categorys widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
    <span>CATEGORYS</span>
  </div>
  <div class="widget-body">
    <ul class="categorys-list">
      
        <li class="categorys-list-item">
          <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
            学习笔记 (14)
          </a>
        </li>
      
        <li class="categorys-list-item">
          <a href="/categories/%E6%95%99%E7%A8%8B/">
            教程 (5)
          </a>
        </li>
      
    </ul>
  </div>
</section>

      <section class="widget-tags widget-item  layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
    <span>TAGS</span>
  </div>
  <div class="widget-body">
    <div class="tags-cloud">
      <a href="/tags/Hadoop/" style="font-size: 10px;" class="tags-cloud-0">Hadoop</a> <a href="/tags/Python/" style="font-size: 15px;" class="tags-cloud-5">Python</a> <a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 15px;" class="tags-cloud-5">前端</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 10px;" class="tags-cloud-0">数据库</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 20px;" class="tags-cloud-10">数据结构</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 10px;" class="tags-cloud-0">机器学习</a>
    </div>
  </div>
</section>
    </div>
  </article>
</div>

    <!-- footer container -->
<footer id="footer" class="footer">
  <div class="footer-container">
    
    <div class="social-icons">
      
        
      
        
      
        
      
        
          <a href="https://github.com/chenthesky" class="soft-size--primary soft-style--box" target="_blank" rel="noopener noreferrer">
            <svg class="icon icon-github" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M64.6 512c0 195.6 125.4 361.9 300.1 422.9 23.5 5.9 19.9-10.8 19.9-22.2v-77.6c-135.8 15.9-141.3-74-150.5-89-18.5-31.5-61.9-39.5-49-54.5 31-15.9 62.5 4 98.9 58 26.4 39.1 77.9 32.5 104.1 26 5.7-23.5 17.9-44.5 34.7-60.9-140.7-25.2-199.4-111.1-199.4-213.3 0-49.5 16.4-95.1 48.4-131.8-20.4-60.6 1.9-112.4 4.9-120.1 58.2-5.2 118.5 41.6 123.3 45.3 33.1-8.9 70.8-13.7 112.9-13.7 42.4 0 80.3 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.4-43.9 2.9 7.7 24.7 58.3 5.5 118.1 32.5 36.8 49 82.8 49 132.4 0 102.3-59 188.3-200.2 213.2 23.5 23.3 38.1 55.5 38.1 91.1v112.7c0.8 9 0 17.9 15.1 17.9C832.7 877 960.4 709.4 960.4 512.1c0-247.5-200.6-447.9-447.9-447.9C265 64.1 64.6 264.5 64.6 512z"></path>
</svg>
          </a>
        
      
        
      
    </div>
     
    <p>&copy; 2024 <a href="/" target="_blank">Ty Leo</a></p>

    

    <p>Powered by <a href="https://hexo.io" target="_blank" rel="noopener noreferrer">Hexo</a></p>

    <p>
      <a href="javascript:;" id="theme-light">🌞 浅色</a>
      <a href="javascript:;" id="theme-dark">🌛 深色</a>
      <a href="javascript:;" id="theme-auto">🤖️ 自动</a>
    </p>
  </div>
</footer>
  </div>
  <div class="back-to-top-fixed soft-size--round soft-style--box">
    <svg class="icon icon-back-to-top" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
      <path d="M725.333333 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8l-213.333333-213.333333c-17.066667-17.066667-17.066667-42.666667 0-59.733333s42.666667-17.066667 59.733333 0l213.333333 213.333333c17.066667 17.066667 17.066667 42.666667 0 59.733333C746.666667 422.4 738.133333 426.666667 725.333333 426.666667z"></path>
      <path d="M298.666667 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8-17.066667-17.066667-17.066667-42.666667 0-59.733333l213.333333-213.333333c17.066667-17.066667 42.666667-17.066667 59.733333 0s17.066667 42.666667 0 59.733333l-213.333333 213.333333C320 422.4 311.466667 426.666667 298.666667 426.666667z"></path>
      <path d="M512 896c-25.6 0-42.666667-17.066667-42.666667-42.666667L469.333333 170.666667c0-25.6 17.066667-42.666667 42.666667-42.666667s42.666667 17.066667 42.666667 42.666667l0 682.666667C554.666667 878.933333 537.6 896 512 896z"></path>
    </svg>
  </div>
  
  <!-- aplayer -->


<!-- dplayer -->


<!-- copy button  -->
<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script>

<!-- https://clipboardjs.com/ -->









  


  


  




<script src="/js/script.js"></script>


  
  <!-- 尾部用户自定义相关内容 -->
<div>
    <link rel="stylesheet" href="/dist/APlayer.min.css"> 
    <div id="aplayer"></div>
    <script type="text/javascript" src="/dist/APlayer.min.js"></script>
    <script type="text/javascript" src="https://unpkg.com/dplayer@1.27.1/dist/DPlayer.min.js"></script>
    <script type="text/javascript" src="/js/diy/music.js"></script>
</div>
<div>    
    <script type="text/javascript" src='//unpkg.com/valine/dist/Valine.min.js'></script>
</div>



</body>
  <script>
  // 对所有链接跳转事件绑定pjax容器pjax-container 
    $(document).pjax('a', '#pjax-container', {
      fragment:'#pjax-container',
      timeout:8000
      });
    // $(document).on('ready pjax:beforeReplace', function (event) {
    //   valine.setPath(pathname);
    //   });   
  </script> 
</html>
